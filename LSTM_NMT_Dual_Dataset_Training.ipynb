{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:08.035847Z",
     "iopub.status.busy": "2025-04-22T10:43:08.035581Z",
     "iopub.status.idle": "2025-04-22T10:43:08.042745Z",
     "shell.execute_reply": "2025-04-22T10:43:08.041937Z",
     "shell.execute_reply.started": "2025-04-22T10:43:08.035807Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hindienglish-corpora', 'english-hindi-rnn-trainedmodelfiles']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load IIT-B parallel Corpus Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:09.014504Z",
     "iopub.status.busy": "2025-04-22T10:43:09.014220Z",
     "iopub.status.idle": "2025-04-22T10:43:09.017751Z",
     "shell.execute_reply": "2025-04-22T10:43:09.016929Z",
     "shell.execute_reply.started": "2025-04-22T10:43:09.014447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# lines=pd.read_csv(\"../input/Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')\n",
    "# lines = pd.read_csv(\"/kaggle/input/english-hindi-rnn-trainedmodelfiles/train.csv\")\n",
    "# dataset_used=\"iitb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TED Talks Parallel Corpus Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:10.184895Z",
     "iopub.status.busy": "2025-04-22T10:43:10.184627Z",
     "iopub.status.idle": "2025-04-22T10:43:10.756685Z",
     "shell.execute_reply": "2025-04-22T10:43:10.755950Z",
     "shell.execute_reply.started": "2025-04-22T10:43:10.184843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# lines=pd.read_csv(\"../input/Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')\n",
    "lines = pd.read_csv(\"/kaggle/input/hindienglish-corpora/Hindi_English_Truncated_Corpus.csv\")\n",
    "dataset_used=\"ted_talks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:10.758232Z",
     "iopub.status.busy": "2025-04-22T10:43:10.757837Z",
     "iopub.status.idle": "2025-04-22T10:43:10.799774Z",
     "shell.execute_reply": "2025-04-22T10:43:10.799175Z",
     "shell.execute_reply.started": "2025-04-22T10:43:10.758021Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tides        50000\n",
      "ted          39881\n",
      "indic2012    37726\n",
      "Name: source, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if(dataset_used == \"ted_talks\"):\n",
    "    print(lines['source'].value_counts())\n",
    "    lines=lines[lines['source']=='ted']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:10.901407Z",
     "iopub.status.busy": "2025-04-22T10:43:10.901215Z",
     "iopub.status.idle": "2025-04-22T10:43:10.910553Z",
     "shell.execute_reply": "2025-04-22T10:43:10.909825Z",
     "shell.execute_reply.started": "2025-04-22T10:43:10.901377Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what needs to be done.</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not paying attention.</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ted</td>\n",
       "      <td>And who are we to say, even, that they are wrong</td>\n",
       "      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ted</td>\n",
       "      <td>So there is some sort of justice</td>\n",
       "      <td>तो वहाँ न्याय है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ted</td>\n",
       "      <td>This changed slowly</td>\n",
       "      <td>धीरे धीरे ये सब बदला</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ted</td>\n",
       "      <td>were being produced.</td>\n",
       "      <td>उत्पन्न नहीं कि जाती थी.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ted</td>\n",
       "      <td>And you can see, this LED is going to glow.</td>\n",
       "      <td>और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ted</td>\n",
       "      <td>to turn on the lights or to bring him a glass of water,</td>\n",
       "      <td>लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ted</td>\n",
       "      <td>Can you imagine saying that?</td>\n",
       "      <td>क्या आप ये कल्पना कर सकते है</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source                                                  english_sentence                                                        hindi_sentence\n",
       "0   ted    politicians do not have permission to do what needs to be done.   राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .\n",
       "1   ted    I'd like to tell you about one such child,                        मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,                  \n",
       "3   ted    what we really mean is that they're bad at not paying attention.  हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते                      \n",
       "7   ted    And who are we to say, even, that they are wrong                  और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं                    \n",
       "13  ted    So there is some sort of justice                                  तो वहाँ न्याय है                                                    \n",
       "23  ted    This changed slowly                                               धीरे धीरे ये सब बदला                                                \n",
       "26  ted    were being produced.                                              उत्पन्न नहीं कि जाती थी.                                            \n",
       "30  ted    And you can see, this LED is going to glow.                       और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।                        \n",
       "32  ted    to turn on the lights or to bring him a glass of water,           लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,                     \n",
       "35  ted    Can you imagine saying that?                                      क्या आप ये कल्पना कर सकते है                                        "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtering null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:12.847479Z",
     "iopub.status.busy": "2025-04-22T10:43:12.847239Z",
     "iopub.status.idle": "2025-04-22T10:43:12.862416Z",
     "shell.execute_reply": "2025-04-22T10:43:12.861700Z",
     "shell.execute_reply.started": "2025-04-22T10:43:12.847443Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source              0\n",
       "english_sentence    0\n",
       "hindi_sentence      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(lines).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:13.029594Z",
     "iopub.status.busy": "2025-04-22T10:43:13.029307Z",
     "iopub.status.idle": "2025-04-22T10:43:13.046140Z",
     "shell.execute_reply": "2025-04-22T10:43:13.045378Z",
     "shell.execute_reply.started": "2025-04-22T10:43:13.029528Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what needs to be done.</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not paying attention.</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ted</td>\n",
       "      <td>And who are we to say, even, that they are wrong</td>\n",
       "      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ted</td>\n",
       "      <td>So there is some sort of justice</td>\n",
       "      <td>तो वहाँ न्याय है</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source                                                  english_sentence                                                        hindi_sentence\n",
       "0   ted    politicians do not have permission to do what needs to be done.   राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .\n",
       "1   ted    I'd like to tell you about one such child,                        मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,                  \n",
       "3   ted    what we really mean is that they're bad at not paying attention.  हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते                      \n",
       "7   ted    And who are we to say, even, that they are wrong                  और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं                    \n",
       "13  ted    So there is some sort of justice                                  तो वहाँ न्याय है                                                    "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_text_col=\"\"\n",
    "hin_text_col=\"\"\n",
    "if dataset_used==\"iitb\":\n",
    "    eng_text_col=\"eng_text\"\n",
    "elif dataset_used==\"ted_talks\":\n",
    "    eng_text_col=\"english_sentence\"\n",
    "lines=lines[~pd.isnull(lines[eng_text_col])]\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the dulpicate tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:13.126779Z",
     "iopub.status.busy": "2025-04-22T10:43:13.126575Z",
     "iopub.status.idle": "2025-04-22T10:43:13.170202Z",
     "shell.execute_reply": "2025-04-22T10:43:13.169675Z",
     "shell.execute_reply.started": "2025-04-22T10:43:13.126745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lines.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:13.311831Z",
     "iopub.status.busy": "2025-04-22T10:43:13.311591Z",
     "iopub.status.idle": "2025-04-22T10:43:13.384727Z",
     "shell.execute_reply": "2025-04-22T10:43:13.383994Z",
     "shell.execute_reply.started": "2025-04-22T10:43:13.311784Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38803</td>\n",
       "      <td>38803</td>\n",
       "      <td>38803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>38629</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ted</td>\n",
       "      <td>(Applause)</td>\n",
       "      <td>धन्यवाद |</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>38803</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source english_sentence hindi_sentence\n",
       "count   38803  38803            38803        \n",
       "unique  1      38629            38743        \n",
       "top     ted    (Applause)       धन्यवाद |    \n",
       "freq    38803  39               4            "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the column eng_text to english_sentence and hin_text to hindi_sentence\n",
    "if dataset_used==\"iitb\":\n",
    "    lines.rename(columns={'eng_text': 'english_sentence', 'hindi_text': 'hindi_sentence'}, inplace=True)\n",
    "lines.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Let us pick any 25000 rows from the dataset for TED talks and 1,00,000 rows for IIT-B dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:13.800841Z",
     "iopub.status.busy": "2025-04-22T10:43:13.800554Z",
     "iopub.status.idle": "2025-04-22T10:43:13.812892Z",
     "shell.execute_reply": "2025-04-22T10:43:13.812160Z",
     "shell.execute_reply.started": "2025-04-22T10:43:13.800785Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if dataset_used==\"iitb\":\n",
    "    lines=lines.sample(n=100000,random_state=42)\n",
    "elif dataset_used==\"ted_talks\":\n",
    "    lines=lines.sample(n=25000,random_state=42)\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we convert all the english sentences to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:13.876159Z",
     "iopub.status.busy": "2025-04-22T10:43:13.875846Z",
     "iopub.status.idle": "2025-04-22T10:43:13.900414Z",
     "shell.execute_reply": "2025-04-22T10:43:13.897838Z",
     "shell.execute_reply.started": "2025-04-22T10:43:13.876109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
    "# lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove all digits from sentences as they dont play any role in transaltion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:14.049946Z",
     "iopub.status.busy": "2025-04-22T10:43:14.049705Z",
     "iopub.status.idle": "2025-04-22T10:43:14.285513Z",
     "shell.execute_reply": "2025-04-22T10:43:14.284749Z",
     "shell.execute_reply.started": "2025-04-22T10:43:14.049910Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert to string and remove digits\n",
    "# Remove all numbers from text\n",
    "import string\n",
    "remove_digits = str.maketrans('', '', string.digits)\n",
    "lines['english_sentence'] = lines['english_sentence'].astype(str).apply(lambda x: x.translate(remove_digits))\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].astype(str).apply(lambda x: x.translate(remove_digits))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove quotes and punctions from sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:14.336594Z",
     "iopub.status.busy": "2025-04-22T10:43:14.336342Z",
     "iopub.status.idle": "2025-04-22T10:43:14.402560Z",
     "shell.execute_reply": "2025-04-22T10:43:14.401955Z",
     "shell.execute_reply.started": "2025-04-22T10:43:14.336544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Remove quotes\n",
    "\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:14.404002Z",
     "iopub.status.busy": "2025-04-22T10:43:14.403729Z",
     "iopub.status.idle": "2025-04-22T10:43:14.706089Z",
     "shell.execute_reply": "2025-04-22T10:43:14.705365Z",
     "shell.execute_reply.started": "2025-04-22T10:43:14.403944Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove digits from devanagri scripts as hindi script has different digits and strip extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:14.707743Z",
     "iopub.status.busy": "2025-04-22T10:43:14.707449Z",
     "iopub.status.idle": "2025-04-22T10:43:15.102143Z",
     "shell.execute_reply": "2025-04-22T10:43:15.101385Z",
     "shell.execute_reply.started": "2025-04-22T10:43:14.707690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add start and end tokens to target sequence to signal decoder to start and end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:15.104246Z",
     "iopub.status.busy": "2025-04-22T10:43:15.103880Z",
     "iopub.status.idle": "2025-04-22T10:43:15.123396Z",
     "shell.execute_reply": "2025-04-22T10:43:15.122791Z",
     "shell.execute_reply.started": "2025-04-22T10:43:15.104182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:15.124855Z",
     "iopub.status.busy": "2025-04-22T10:43:15.124623Z",
     "iopub.status.idle": "2025-04-22T10:43:15.138344Z",
     "shell.execute_reply": "2025-04-22T10:43:15.137653Z",
     "shell.execute_reply.started": "2025-04-22T10:43:15.124809Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82040</th>\n",
       "      <td>ted</td>\n",
       "      <td>we still dont know who her parents are who she is</td>\n",
       "      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85038</th>\n",
       "      <td>ted</td>\n",
       "      <td>no keyboard</td>\n",
       "      <td>START_ कोई कुंजीपटल नहीं _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58018</th>\n",
       "      <td>ted</td>\n",
       "      <td>but as far as being a performer</td>\n",
       "      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74470</th>\n",
       "      <td>ted</td>\n",
       "      <td>and this particular balloon</td>\n",
       "      <td>START_ और यह खास गुब्बारा _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122330</th>\n",
       "      <td>ted</td>\n",
       "      <td>and its not as hard as you think integrate climate solutions into all of your innovations</td>\n",
       "      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                                                           english_sentence                                                                                            hindi_sentence\n",
       "82040   ted    we still dont know who her parents are who she is                                          START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END                                 \n",
       "85038   ted    no keyboard                                                                                START_ कोई कुंजीपटल नहीं _END                                                                           \n",
       "58018   ted    but as far as being a performer                                                            START_ लेकिन एक कलाकार होने के साथ _END                                                                 \n",
       "74470   ted    and this particular balloon                                                                START_ और यह खास गुब्बारा _END                                                                          \n",
       "122330  ted    and its not as hard as you think integrate climate solutions into all of your innovations  START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genrate Hind and english vocabulary by storing all the unique words in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:15.139981Z",
     "iopub.status.busy": "2025-04-22T10:43:15.139760Z",
     "iopub.status.idle": "2025-04-22T10:43:15.243181Z",
     "shell.execute_reply": "2025-04-22T10:43:15.242457Z",
     "shell.execute_reply.started": "2025-04-22T10:43:15.139937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Get English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in lines['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in lines['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:15.509744Z",
     "iopub.status.busy": "2025-04-22T10:43:15.509482Z",
     "iopub.status.idle": "2025-04-22T10:43:15.514435Z",
     "shell.execute_reply": "2025-04-22T10:43:15.513810Z",
     "shell.execute_reply.started": "2025-04-22T10:43:15.509705Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14030"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:20.682202Z",
     "iopub.status.busy": "2025-04-22T10:43:20.681869Z",
     "iopub.status.idle": "2025-04-22T10:43:20.686756Z",
     "shell.execute_reply": "2025-04-22T10:43:20.686148Z",
     "shell.execute_reply.started": "2025-04-22T10:43:20.682145Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17544"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hindi_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the length of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:20.840473Z",
     "iopub.status.busy": "2025-04-22T10:43:20.840206Z",
     "iopub.status.idle": "2025-04-22T10:43:20.897102Z",
     "shell.execute_reply": "2025-04-22T10:43:20.896242Z",
     "shell.execute_reply.started": "2025-04-22T10:43:20.840424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:21.000248Z",
     "iopub.status.busy": "2025-04-22T10:43:20.999939Z",
     "iopub.status.idle": "2025-04-22T10:43:21.010467Z",
     "shell.execute_reply": "2025-04-22T10:43:21.009777Z",
     "shell.execute_reply.started": "2025-04-22T10:43:21.000201Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82040</th>\n",
       "      <td>ted</td>\n",
       "      <td>we still dont know who her parents are who she is</td>\n",
       "      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85038</th>\n",
       "      <td>ted</td>\n",
       "      <td>no keyboard</td>\n",
       "      <td>START_ कोई कुंजीपटल नहीं _END</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58018</th>\n",
       "      <td>ted</td>\n",
       "      <td>but as far as being a performer</td>\n",
       "      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74470</th>\n",
       "      <td>ted</td>\n",
       "      <td>and this particular balloon</td>\n",
       "      <td>START_ और यह खास गुब्बारा _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122330</th>\n",
       "      <td>ted</td>\n",
       "      <td>and its not as hard as you think integrate climate solutions into all of your innovations</td>\n",
       "      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                                                           english_sentence                                                                                            hindi_sentence  length_eng_sentence  length_hin_sentence\n",
       "82040   ted    we still dont know who her parents are who she is                                          START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END                                   11                   16                 \n",
       "85038   ted    no keyboard                                                                                START_ कोई कुंजीपटल नहीं _END                                                                             2                    5                  \n",
       "58018   ted    but as far as being a performer                                                            START_ लेकिन एक कलाकार होने के साथ _END                                                                   7                    8                  \n",
       "74470   ted    and this particular balloon                                                                START_ और यह खास गुब्बारा _END                                                                            4                    6                  \n",
       "122330  ted    and its not as hard as you think integrate climate solutions into all of your innovations  START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END  16                   20                 "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:27.388708Z",
     "iopub.status.busy": "2025-04-22T10:43:27.388396Z",
     "iopub.status.idle": "2025-04-22T10:43:27.395807Z",
     "shell.execute_reply": "2025-04-22T10:43:27.395132Z",
     "shell.execute_reply.started": "2025-04-22T10:43:27.388657Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[lines['length_eng_sentence']>30].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filtering sentences which have less than 20 words in sentence in both the source and target language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:27.618232Z",
     "iopub.status.busy": "2025-04-22T10:43:27.617961Z",
     "iopub.status.idle": "2025-04-22T10:43:27.629363Z",
     "shell.execute_reply": "2025-04-22T10:43:27.628525Z",
     "shell.execute_reply.started": "2025-04-22T10:43:27.618192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lines=lines[lines['length_eng_sentence']<=20]\n",
    "lines=lines[lines['length_hin_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:27.899948Z",
     "iopub.status.busy": "2025-04-22T10:43:27.899697Z",
     "iopub.status.idle": "2025-04-22T10:43:27.904506Z",
     "shell.execute_reply": "2025-04-22T10:43:27.903697Z",
     "shell.execute_reply.started": "2025-04-22T10:43:27.899909Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24774, 5)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:28.168284Z",
     "iopub.status.busy": "2025-04-22T10:43:28.168027Z",
     "iopub.status.idle": "2025-04-22T10:43:28.173896Z",
     "shell.execute_reply": "2025-04-22T10:43:28.173244Z",
     "shell.execute_reply.started": "2025-04-22T10:43:28.168247Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  20\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:28.425005Z",
     "iopub.status.busy": "2025-04-22T10:43:28.424749Z",
     "iopub.status.idle": "2025-04-22T10:43:28.429888Z",
     "shell.execute_reply": "2025-04-22T10:43:28.429076Z",
     "shell.execute_reply.started": "2025-04-22T10:43:28.424966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_length_src=max(lines['length_hin_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input_words & target_words: Sorted lists of unique source (English) and target (Hindi, including START_/END_) vocabulary items.\n",
    "- num_encoder_tokens & num_decoder_tokens: Counts of unique tokens for the encoder and decoder vocabularies, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:28.705166Z",
     "iopub.status.busy": "2025-04-22T10:43:28.704883Z",
     "iopub.status.idle": "2025-04-22T10:43:28.728005Z",
     "shell.execute_reply": "2025-04-22T10:43:28.727191Z",
     "shell.execute_reply.started": "2025-04-22T10:43:28.705120Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14030, 17544)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we add 1 to decoder token for padding token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:28.976033Z",
     "iopub.status.busy": "2025-04-22T10:43:28.975754Z",
     "iopub.status.idle": "2025-04-22T10:43:28.979798Z",
     "shell.execute_reply": "2025-04-22T10:43:28.978858Z",
     "shell.execute_reply.started": "2025-04-22T10:43:28.975976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_decoder_tokens += 1 #for zero padding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input/target_token_index: Dictionaries mapping source (English) and target (Hindi) words/tokens to unique integer indices (starting from 1).\n",
    "- reverse_input/target_char_index: Dictionaries mapping the integer indices back to their corresponding source and target words/tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:29.253277Z",
     "iopub.status.busy": "2025-04-22T10:43:29.252947Z",
     "iopub.status.idle": "2025-04-22T10:43:29.272970Z",
     "shell.execute_reply": "2025-04-22T10:43:29.271990Z",
     "shell.execute_reply.started": "2025-04-22T10:43:29.253224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:29.500605Z",
     "iopub.status.busy": "2025-04-22T10:43:29.500396Z",
     "iopub.status.idle": "2025-04-22T10:43:29.512297Z",
     "shell.execute_reply": "2025-04-22T10:43:29.511524Z",
     "shell.execute_reply.started": "2025-04-22T10:43:29.500568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:29.807265Z",
     "iopub.status.busy": "2025-04-22T10:43:29.806997Z",
     "iopub.status.idle": "2025-04-22T10:43:29.823854Z",
     "shell.execute_reply": "2025-04-22T10:43:29.823272Z",
     "shell.execute_reply.started": "2025-04-22T10:43:29.807224Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118274</th>\n",
       "      <td>ted</td>\n",
       "      <td>helping these people to speak up their minds</td>\n",
       "      <td>START_ इसकी मदद से लोगों ने अपनी मन की बात कही _END</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117489</th>\n",
       "      <td>ted</td>\n",
       "      <td>in firemen in climbers in policemen</td>\n",
       "      <td>START_ फायरब्रिगेड वालों में पर्वतारोहियों में पुलिसकर्मियों में _END</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110462</th>\n",
       "      <td>ted</td>\n",
       "      <td>for us were very facile around electricity</td>\n",
       "      <td>START_ हमारे लिए बिजली से जुड़ी चीजे बहुत आसान हैं _END</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109360</th>\n",
       "      <td>ted</td>\n",
       "      <td>is easy to overcome</td>\n",
       "      <td>START_ वास्तव में बहुत ही आसानी से किया जा सकता है _END</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54759</th>\n",
       "      <td>ted</td>\n",
       "      <td>they want the washing machine in exactly the same way</td>\n",
       "      <td>START_ बिल्कुल उसी तरह इन्हें भी वाशिंग मशीन चाहिए _END</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>ted</td>\n",
       "      <td>this is called a cycle valve tube</td>\n",
       "      <td>START_ इसे साइकिल का वाल्व ट्यूब कहते हैं। _END</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126499</th>\n",
       "      <td>ted</td>\n",
       "      <td>i wrote exactly the kinds of stories i was reading</td>\n",
       "      <td>START_ मैं वैसी ही कहानियां लिख रही थी जैसी मैं उस समय पढ़ रही थी _END</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62451</th>\n",
       "      <td>ted</td>\n",
       "      <td>and what did we talk about</td>\n",
       "      <td>START_ तो हम क्या बोलते _END</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86494</th>\n",
       "      <td>ted</td>\n",
       "      <td>and those top percent have been the best in the world</td>\n",
       "      <td>START_ और वो प्रतिशत दुनिया में सर्वश्रेष्ठ हैं _END</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82742</th>\n",
       "      <td>ted</td>\n",
       "      <td>were going to have about eight billion perhaps more people</td>\n",
       "      <td>START_ संसार में अरब या उस से भी ज्यादा लोग होंगे _END</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                            english_sentence                                                          hindi_sentence  length_eng_sentence  length_hin_sentence\n",
       "118274  ted    helping these people to speak up their minds                START_ इसकी मदद से लोगों ने अपनी मन की बात कही _END                     8                    12                 \n",
       "117489  ted    in firemen in climbers in policemen                         START_ फायरब्रिगेड वालों में पर्वतारोहियों में पुलिसकर्मियों में _END   6                    9                  \n",
       "110462  ted    for us were very facile around electricity                  START_ हमारे लिए बिजली से जुड़ी चीजे बहुत आसान हैं _END                 7                    11                 \n",
       "109360  ted    is easy to overcome                                         START_ वास्तव में बहुत ही आसानी से किया जा सकता है _END                 4                    12                 \n",
       "54759   ted    they want the washing machine in exactly the same way       START_ बिल्कुल उसी तरह इन्हें भी वाशिंग मशीन चाहिए _END                 10                   10                 \n",
       "493     ted    this is called a cycle valve tube                           START_ इसे साइकिल का वाल्व ट्यूब कहते हैं। _END                         7                    9                  \n",
       "126499  ted    i wrote exactly the kinds of stories i was reading          START_ मैं वैसी ही कहानियां लिख रही थी जैसी मैं उस समय पढ़ रही थी _END  10                   16                 \n",
       "62451   ted    and what did we talk about                                  START_ तो हम क्या बोलते _END                                            6                    6                  \n",
       "86494   ted    and those top percent have been the best in the world       START_ और वो प्रतिशत दुनिया में सर्वश्रेष्ठ हैं _END                    11                   9                  \n",
       "82742   ted    were going to have about eight billion perhaps more people  START_ संसार में अरब या उस से भी ज्यादा लोग होंगे _END                  10                   12                 "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:31.231374Z",
     "iopub.status.busy": "2025-04-22T10:43:31.231063Z",
     "iopub.status.idle": "2025-04-22T10:43:31.243966Z",
     "shell.execute_reply": "2025-04-22T10:43:31.243164Z",
     "shell.execute_reply.started": "2025-04-22T10:43:31.231319Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19819,), (4955,))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = lines['english_sentence'], lines['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us save this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:35.887541Z",
     "iopub.status.busy": "2025-04-22T10:43:35.887262Z",
     "iopub.status.idle": "2025-04-22T10:43:35.903449Z",
     "shell.execute_reply": "2025-04-22T10:43:35.902836Z",
     "shell.execute_reply.started": "2025-04-22T10:43:35.887502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')\n",
    "y_test.to_pickle('y_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we create this function generate batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:36.149182Z",
     "iopub.status.busy": "2025-04-22T10:43:36.148920Z",
     "iopub.status.idle": "2025-04-22T10:43:36.156028Z",
     "shell.execute_reply": "2025-04-22T10:43:36.154901Z",
     "shell.execute_reply.started": "2025-04-22T10:43:36.149136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **Encoder:**\n",
    "    *   Takes variable-length sequences of integer token indices.\n",
    "    *   Embeds these indices into dense vectors (`Embedding` layer).\n",
    "    *   Processes the embedded sequence with an LSTM (`encoder_lstm`).\n",
    "    *   Captures the input sequence's context in its final hidden state (`state_h`) and cell state (`state_c`). These `encoder_states` are the encoder's output.\n",
    "\n",
    "*   **Decoder:**\n",
    "    *   Takes variable-length sequences of target token indices (`decoder_inputs`, typically shifted right during training).\n",
    "    *   Embeds these target indices using a separate `Embedding` layer (`dec_emb_layer`).\n",
    "    *   Processes the embedded sequence with its own LSTM (`decoder_lstm`).\n",
    "    *   **Key Connection:** The `decoder_lstm` is initialized with the `encoder_states` (`initial_state=encoder_states`), providing it context from the source sequence.\n",
    "    *   Configured with `return_sequences=True` to output a hidden state for *each* timestep.\n",
    "\n",
    "*   **Output Layer:**\n",
    "    *   A `Dense` layer with `softmax` activation is applied to the decoder LSTM's output sequence.\n",
    "    *   This layer predicts the probability distribution over the entire target vocabulary (`num_decoder_tokens`) for each position in the output sequence.\n",
    "\n",
    "*   **Training Model (`model`):**\n",
    "    *   Defined with `encoder_inputs` and `decoder_inputs` as inputs.\n",
    "    *   Produces `decoder_outputs` (the sequence of probability distributions).\n",
    "    *   Compiled using `categorical_crossentropy` loss, suitable for comparing the predicted distributions against one-hot encoded target sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:37.479272Z",
     "iopub.status.busy": "2025-04-22T10:43:37.478939Z",
     "iopub.status.idle": "2025-04-22T10:43:37.482842Z",
     "shell.execute_reply": "2025-04-22T10:43:37.482093Z",
     "shell.execute_reply.started": "2025-04-22T10:43:37.479208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "latent_dim=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:38.308221Z",
     "iopub.status.busy": "2025-04-22T10:43:38.307917Z",
     "iopub.status.idle": "2025-04-22T10:43:38.738791Z",
     "shell.execute_reply": "2025-04-22T10:43:38.738155Z",
     "shell.execute_reply.started": "2025-04-22T10:43:38.308167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:43.900607Z",
     "iopub.status.busy": "2025-04-22T10:43:43.900369Z",
     "iopub.status.idle": "2025-04-22T10:43:44.424673Z",
     "shell.execute_reply": "2025-04-22T10:43:44.424070Z",
     "shell.execute_reply.started": "2025-04-22T10:43:43.900571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:44.426388Z",
     "iopub.status.busy": "2025-04-22T10:43:44.426088Z",
     "iopub.status.idle": "2025-04-22T10:43:44.463962Z",
     "shell.execute_reply": "2025-04-22T10:43:44.463259Z",
     "shell.execute_reply.started": "2025-04-22T10:43:44.426329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:43:44.613148Z",
     "iopub.status.busy": "2025-04-22T10:43:44.612844Z",
     "iopub.status.idle": "2025-04-22T10:43:44.619269Z",
     "shell.execute_reply": "2025-04-22T10:43:44.617942Z",
     "shell.execute_reply.started": "2025-04-22T10:43:44.613089Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    4209000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 300)    5263500     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 300), (None, 721200      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 300),  721200      embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 17545)  5281045     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 16,195,945\n",
      "Trainable params: 16,195,945\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:44:00.465136Z",
     "iopub.status.busy": "2025-04-22T10:44:00.464861Z",
     "iopub.status.idle": "2025-04-22T10:44:00.468534Z",
     "shell.execute_reply": "2025-04-22T10:44:00.467854Z",
     "shell.execute_reply.started": "2025-04-22T10:44:00.465092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping and Adam Optimizer\n",
    "Early Stopping:\n",
    "\n",
    "- Prevents Overfitting: Stops training when validation performance stops improving.\n",
    "- Saves Time/Resources: Avoids unnecessary epochs, potentially finding a good model faster.\n",
    "\n",
    "\n",
    "Adam Optimizer:\n",
    "\n",
    "- Adaptive Learning Rates: Calculates individual learning rates for each parameter.\n",
    "- Combines Momentum & RMSprop: Leverages the strengths of both methods for often faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T10:44:01.443305Z",
     "iopub.status.busy": "2025-04-22T10:44:01.442960Z",
     "iopub.status.idle": "2025-04-22T11:10:04.013812Z",
     "shell.execute_reply": "2025-04-22T11:10:04.013125Z",
     "shell.execute_reply.started": "2025-04-22T10:44:01.443245Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/100\n",
      "154/154 [==============================] - 71s 460ms/step - loss: 6.9160 - val_loss: 6.4758\n",
      "Epoch 2/100\n",
      "154/154 [==============================] - 68s 439ms/step - loss: 6.3541 - val_loss: 6.3458\n",
      "Epoch 3/100\n",
      "154/154 [==============================] - 68s 439ms/step - loss: 6.0463 - val_loss: 6.0191\n",
      "Epoch 4/100\n",
      "154/154 [==============================] - 67s 438ms/step - loss: 5.6991 - val_loss: 5.8179\n",
      "Epoch 5/100\n",
      "154/154 [==============================] - 67s 436ms/step - loss: 5.4141 - val_loss: 5.6876\n",
      "Epoch 6/100\n",
      "154/154 [==============================] - 68s 441ms/step - loss: 5.1651 - val_loss: 5.5695\n",
      "Epoch 7/100\n",
      "154/154 [==============================] - 68s 439ms/step - loss: 4.9194 - val_loss: 5.4784\n",
      "Epoch 8/100\n",
      "154/154 [==============================] - 67s 434ms/step - loss: 4.6884 - val_loss: 5.4086\n",
      "Epoch 9/100\n",
      "154/154 [==============================] - 67s 434ms/step - loss: 4.4730 - val_loss: 5.3552\n",
      "Epoch 10/100\n",
      "154/154 [==============================] - 67s 433ms/step - loss: 4.2638 - val_loss: 5.3165\n",
      "Epoch 11/100\n",
      "154/154 [==============================] - 67s 435ms/step - loss: 4.0556 - val_loss: 5.2948\n",
      "Epoch 12/100\n",
      "154/154 [==============================] - 68s 442ms/step - loss: 3.8525 - val_loss: 5.2894\n",
      "Epoch 13/100\n",
      "154/154 [==============================] - 68s 440ms/step - loss: 3.6650 - val_loss: 5.2905\n",
      "Epoch 14/100\n",
      "154/154 [==============================] - 68s 439ms/step - loss: 3.4787 - val_loss: 5.2890\n",
      "Epoch 15/100\n",
      "154/154 [==============================] - 68s 441ms/step - loss: 3.2935 - val_loss: 5.2886\n",
      "Epoch 16/100\n",
      "154/154 [==============================] - 68s 445ms/step - loss: 3.1096 - val_loss: 5.3102\n",
      "Epoch 17/100\n",
      "154/154 [==============================] - 69s 449ms/step - loss: 2.9382 - val_loss: 5.3246\n",
      "Epoch 18/100\n",
      "154/154 [==============================] - 68s 444ms/step - loss: 2.7774 - val_loss: 5.3470\n",
      "Epoch 19/100\n",
      "154/154 [==============================] - 68s 440ms/step - loss: 2.6177 - val_loss: 5.3801\n",
      "Epoch 20/100\n",
      "154/154 [==============================] - 68s 441ms/step - loss: 2.4667 - val_loss: 5.4049\n",
      "Epoch 21/100\n",
      "154/154 [==============================] - 68s 441ms/step - loss: 2.3188 - val_loss: 5.4502\n",
      "Epoch 22/100\n",
      "154/154 [==============================] - 68s 444ms/step - loss: 2.1740 - val_loss: 5.4549\n",
      "Epoch 23/100\n",
      "154/154 [==============================] - 68s 443ms/step - loss: 2.0359 - val_loss: 5.5086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7dd276126240>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size,\n",
    "                    callbacks=[early_stop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Isolates the Encoder: It creates a separate encoder_model that just takes your input sentence and produces the final \"context\" states (the summary of the input).\n",
    "- Prepares for State Input: It sets up special input placeholders (decoder_state_input_h/c) specifically designed to receive the decoder's internal memory (states) from the previous step during generation.\n",
    "- Defines One Decoder Step: It wires up the trained decoder layers (embedding, LSTM, dense) so they can take a single input word and the previous step's states, then output the probabilities for the next word and the updated states.\n",
    "- Builds the Inference Decoder: It combines the single-word input, the state inputs, the single-step processing, and the outputs (probabilities + new states) into the final decoder_model used repeatedly in a loop to generate the translation word by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T11:10:50.773482Z",
     "iopub.status.busy": "2025-04-22T11:10:50.773238Z",
     "iopub.status.idle": "2025-04-22T11:10:50.921634Z",
     "shell.execute_reply": "2025-04-22T11:10:50.920952Z",
     "shell.execute_reply.started": "2025-04-22T11:10:50.773445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function take english sentence as inputs and outputs the decoded sentence in hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T11:10:56.069941Z",
     "iopub.status.busy": "2025-04-22T11:10:56.069684Z",
     "iopub.status.idle": "2025-04-22T11:10:56.075957Z",
     "shell.execute_reply": "2025-04-22T11:10:56.074981Z",
     "shell.execute_reply.started": "2025-04-22T11:10:56.069902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T11:11:00.113110Z",
     "iopub.status.busy": "2025-04-22T11:11:00.112834Z",
     "iopub.status.idle": "2025-04-22T11:11:00.119461Z",
     "shell.execute_reply": "2025-04-22T11:11:00.118573Z",
     "shell.execute_reply.started": "2025-04-22T11:11:00.113068Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10538     childrens books                                      \n",
       "26526     one for yourself and one for others                  \n",
       "97791     thats why in negotiations often when things get tough\n",
       "102198    this is a degeneration of the retina                 \n",
       "60523     i know what i have just said is simply not obvious   \n",
       "Name: english_sentence, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_test=X_test\n",
    "lines_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculating bleu-1 and bleu-4 score in test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T11:11:02.203517Z",
     "iopub.status.busy": "2025-04-22T11:11:02.203235Z",
     "iopub.status.idle": "2025-04-22T11:11:13.236205Z",
     "shell.execute_reply": "2025-04-22T11:11:13.235460Z",
     "shell.execute_reply.started": "2025-04-22T11:11:02.203465Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final BLEU-4 Score: 0.0200\n",
      "BLEU-1 Score: 0.1899\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X=X_test\n",
    "y=y_test\n",
    "# X, y = lines_test['english_sentence'], lines_test['hindi_sentence']\n",
    "test_gen = generate_batch(X, y, batch_size = 1)\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "translations = []\n",
    "references = []\n",
    "english = []\n",
    "# for idx, row in lines_test.iterrows():\n",
    "#     trans = decode_sequence(row['english_sentence'])[:-4]\n",
    "#     references.append(row['hindi_sentence'])\n",
    "#     translated.append(trans)\n",
    "for i in range(500):\n",
    "    (input_seq, actual_output), _ = next(test_gen)\n",
    "    trans = decode_sequence(input_seq)\n",
    "    # print(X[i:i+1].values[0])\n",
    "    # print(y[i:i+1].values[0][6:-4])\n",
    "    # print(trans[:-4],end = \"\\n\\n\")\n",
    "    references.append(y[i:i+1].values[0][6:-4])\n",
    "    translations.append(trans[:-4])\n",
    "    english.append(X[i:i+1].values[0])\n",
    "bleu_score = corpus_bleu(\n",
    "    [[ref.split()] for ref in references],  \n",
    "    [trans.split() for trans in translations],\n",
    "    smoothing_function=SmoothingFunction().method1\n",
    ")\n",
    "print(f\"\\nFinal BLEU-4 Score: {bleu_score:.4f}\")\n",
    "\n",
    "bleu1_score = corpus_bleu(\n",
    "    [[ref.split()] for ref in references],\n",
    "    [trans.split() for trans in translations],\n",
    "    weights=(1, 0, 0, 0),  # Only unigram\n",
    "    smoothing_function=SmoothingFunction().method1\n",
    ")\n",
    "print(f\"BLEU-1 Score: {bleu1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "printing some sample sentences translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T11:16:40.378496Z",
     "iopub.status.busy": "2025-04-22T11:16:40.378238Z",
     "iopub.status.idle": "2025-04-22T11:16:40.390211Z",
     "shell.execute_reply": "2025-04-22T11:16:40.389456Z",
     "shell.execute_reply.started": "2025-04-22T11:16:40.378459Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>hi</th>\n",
       "      <th>translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>childrens books</td>\n",
       "      <td>बच्चों की किताबे</td>\n",
       "      <td>अपने पति से पूछा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one for yourself and one for others</td>\n",
       "      <td>एक अपने लिये और एक बाकी सब के लिये ।</td>\n",
       "      <td>एक दूसरे के लिए और अधिक कम करने के लिए</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thats why in negotiations often when things get tough</td>\n",
       "      <td>इसिलिये जब मसले हल करते समय स्थिति कठिन हो जाती है</td>\n",
       "      <td>तो लोग लोग उन लोगों को भी नहीं कर सकते हैं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is a degeneration of the retina</td>\n",
       "      <td>यह रेटिना के अध पतन है</td>\n",
       "      <td>यह एक बहुत ही एक चक्र है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i know what i have just said is simply not obvious</td>\n",
       "      <td>मै जानती हूँ मैने अभी जो कहा वो प्रत्यक्ष रूप से स्पष्ट नही है</td>\n",
       "      <td>मैं नहीं जानता कि मैं यह नहीं जानता कि</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      en                                                                hi                                    translated\n",
       "0  childrens books                                         बच्चों की किताबे                                                  अपने पति से पूछा                           \n",
       "1  one for yourself and one for others                     एक अपने लिये और एक बाकी सब के लिये ।                              एक दूसरे के लिए और अधिक कम करने के लिए     \n",
       "2  thats why in negotiations often when things get tough   इसिलिये जब मसले हल करते समय स्थिति कठिन हो जाती है                तो लोग लोग उन लोगों को भी नहीं कर सकते हैं \n",
       "3  this is a degeneration of the retina                    यह रेटिना के अध पतन है                                            यह एक बहुत ही एक चक्र है                   \n",
       "4  i know what i have just said is simply not obvious      मै जानती हूँ मैने अभी जो कहा वो प्रत्यक्ष रूप से स्पष्ट नही है    मैं नहीं जानता कि मैं यह नहीं जानता कि     "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_trans_df_test = pd.DataFrame({\n",
    "    \"en\" : english,\n",
    "    \"hi\" : references,\n",
    "    \"translated\" : translations\n",
    "})\n",
    "final_trans_df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T11:17:11.149749Z",
     "iopub.status.busy": "2025-04-22T11:17:11.149452Z",
     "iopub.status.idle": "2025-04-22T11:17:12.240131Z",
     "shell.execute_reply": "2025-04-22T11:17:12.239459Z",
     "shell.execute_reply.started": "2025-04-22T11:17:11.149696Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_1/while/Exit_2:0' shape=(?, 300) dtype=float32>, <tf.Tensor 'lstm_1_1/while/Exit_3:0' shape=(?, 300) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'input_3_1:0' shape=(?, 300) dtype=float32>, <tf.Tensor 'input_4_1:0' shape=(?, 300) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "# Saving the entire model (including architecture and weights) after training\n",
    "model.save('nmt_model.h5')\n",
    "\n",
    "# Save the encoder model (only the encoder part)\n",
    "encoder_model.save('encoder_model.h5')\n",
    "\n",
    "# Save the decoder model (only the decoder part)\n",
    "decoder_model.save('decoder_model.h5')\n",
    "\n",
    "# Optionally, save the tokenizer mappings\n",
    "import pickle\n",
    "\n",
    "# Save tokenizers (index mappings)\n",
    "with open('input_token_index.pkl', 'wb') as f:\n",
    "    pickle.dump(input_token_index, f)\n",
    "\n",
    "with open('target_token_index.pkl', 'wb') as f:\n",
    "    pickle.dump(target_token_index, f)\n",
    "\n",
    "with open('reverse_input_char_index.pkl', 'wb') as f:\n",
    "    pickle.dump(reverse_input_char_index, f)\n",
    "\n",
    "with open('reverse_target_char_index.pkl', 'wb') as f:\n",
    "    pickle.dump(reverse_target_char_index, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference code for model TED Talks . Loads saved weights and performs inference on it. Computes Bleu scores and supports custom sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:57:53.347203Z",
     "iopub.status.busy": "2025-04-22T14:57:53.346793Z",
     "iopub.status.idle": "2025-04-22T14:57:57.239592Z",
     "shell.execute_reply": "2025-04-22T14:57:57.239037Z",
     "shell.execute_reply.started": "2025-04-22T14:57:53.347002Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "\n",
    "# Load token index files\n",
    "# For IIT B dataset:\n",
    "with open('/kaggle/input/english-hindi-rnn-trainedmodelfiles/input_token_index IITB.pkl', 'rb') as f:\n",
    "    input_token_index = pickle.load(f)\n",
    "with open('/kaggle/input/english-hindi-rnn-trainedmodelfiles/target_token_index IITB.pkl', 'rb') as f:\n",
    "    target_token_index = pickle.load(f)\n",
    "with open('/kaggle/input/english-hindi-rnn-trainedmodelfiles/reverse_input_char_index IITB.pkl', 'rb') as f:\n",
    "    reverse_input_char_index = pickle.load(f)\n",
    "with open('/kaggle/input/english-hindi-rnn-trainedmodelfiles/reverse_target_char_index IITB.pkl', 'rb') as f:\n",
    "    reverse_target_char_index = pickle.load(f)\n",
    "\n",
    "# Load encoder and decoder models\n",
    "encoder_model = load_model('/kaggle/input/english-hindi-rnn-trainedmodelfiles/encoder_model IITB.h5')\n",
    "decoder_model = load_model('/kaggle/input/english-hindi-rnn-trainedmodelfiles/decoder_model IITB.h5')\n",
    "\n",
    "# Load test data\n",
    "X_test = pd.read_pickle('/kaggle/input/english-hindi-rnn-trainedmodelfiles/X_test IITB.pkl')\n",
    "\n",
    "# # For TED Talks dataset\n",
    "# with open('/kaggle/input/english-hindi-rnn-trainedmodelfiles/input_token_index.pkl', 'rb') as f:\n",
    "#     input_token_index = pickle.load(f)\n",
    "# with open('/kaggle/input/english-hindi-rnn-trainedmodelfiles/target_token_index.pkl', 'rb') as f:\n",
    "#     target_token_index = pickle.load(f)\n",
    "# with open('/kaggle/input/english-hindi-rnn-trainedmodelfiles/reverse_input_char_index.pkl', 'rb') as f:\n",
    "#     reverse_input_char_index = pickle.load(f)\n",
    "# with open('/kaggle/input/english-hindi-rnn-trainedmodelfiles/reverse_target_char_index.pkl', 'rb') as f:\n",
    "#     reverse_target_char_index = pickle.load(f)\n",
    "\n",
    "# # Load encoder and decoder models\n",
    "# encoder_model = load_model('/kaggle/input/english-hindi-rnn-trainedmodelfiles/encoder_model.h5')\n",
    "# decoder_model = load_model('/kaggle/input/english-hindi-rnn-trainedmodelfiles/decoder_model.h5')\n",
    "\n",
    "# # Load test data\n",
    "# X_test = pd.read_pickle('/kaggle/input/english-hindi-rnn-trainedmodelfiles/X_test.pkl')\n",
    "\n",
    "# Use the same max lengths as defined during training\n",
    "max_length_src = 20  # From training code analysis\n",
    "max_length_tar = 20  # From training code analysis\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"Preprocess English sentence identically to training data\"\"\"\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(\"'\", '', sentence)\n",
    "    sentence = ''.join(ch for ch in sentence if ch not in string.punctuation)\n",
    "    remove_digits = str.maketrans('', '', string.digits)\n",
    "    sentence = sentence.translate(remove_digits)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = re.sub(\" +\", \" \", sentence)\n",
    "    return sentence\n",
    "\n",
    "def encode_input(sentence):\n",
    "    \"\"\"Convert preprocessed sentence to encoder input format\"\"\"\n",
    "    # Split into words and convert to token indices\n",
    "    tokens = sentence.split()[:max_length_src]  # Truncate if needed\n",
    "    encoded = [input_token_index.get(word, 0) for word in tokens]  # 0 for OOV/padding\n",
    "    # Pad to max_length_src\n",
    "    padded = pad_sequences([encoded], maxlen=max_length_src, padding='post')\n",
    "    return padded\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    \"\"\"Decode sequence using trained models\"\"\"\n",
    "    # Encode input to get initial states\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence with start token\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    decoded_sentence = []\n",
    "    stop_condition = False\n",
    "    while not stop_condition:\n",
    "        # Predict next token\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        # Sample token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = reverse_target_char_index.get(sampled_token_index, '')\n",
    "        \n",
    "        # Check stop condition\n",
    "        if sampled_word == '_END' or len(decoded_sentence) >= max_length_tar:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence.append(sampled_word)\n",
    "        \n",
    "        # Update target sequence and states\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return ' '.join(decoded_sentence[:-1])  # Remove '_END' if present\n",
    "translations = []\n",
    "references = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interactive translation for testing the quality of translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T15:01:47.662583Z",
     "iopub.status.busy": "2025-04-22T15:01:47.662334Z",
     "iopub.status.idle": "2025-04-22T15:01:49.789407Z",
     "shell.execute_reply": "2025-04-22T15:01:49.788684Z",
     "shell.execute_reply.started": "2025-04-22T15:01:47.662545Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the interactive translation tool!\n",
      "Translating sentence: what is your name ?\n",
      "Original Sentence: what is your name ?\n",
      "Translated Sentence: आपका नाम क्या\n",
      "--------------------------------------------------\n",
      "Translating sentence: how are you ?\n",
      "Original Sentence: how are you ?\n",
      "Translated Sentence: तुम कैसे\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the sentence to be translated (or type 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the translation tool. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Assuming necessary imports and functions like preprocess_sentence, encode_input, decode_sequence are defined\n",
    "\n",
    "def interactive_translation():\n",
    "    print(\"Welcome to the interactive translation tool!\")\n",
    "    \n",
    "    # Predefined sentences for testing\n",
    "    predefined_sentences = [\n",
    "        \"what is your name ?\",\n",
    "        \"how are you ?\"\n",
    "    ]\n",
    "    \n",
    "    # Translate predefined sentences first\n",
    "    for sentence in predefined_sentences:\n",
    "        print(f\"Translating sentence: {sentence}\")\n",
    "        preprocessed = preprocess_sentence(sentence)\n",
    "        encoded = encode_input(preprocessed)\n",
    "        translated = decode_sequence(encoded)\n",
    "        print(f\"Original Sentence: {sentence}\")\n",
    "        print(f\"Translated Sentence: {translated}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Now proceed to interactive mode\n",
    "    while True:\n",
    "        # Step 1: Take user input (sentence to be translated)\n",
    "        original_sentence = input(\"Enter the sentence to be translated (or type 'exit' to quit): \")\n",
    "        \n",
    "        # Exit condition\n",
    "        if original_sentence.lower() == 'exit':\n",
    "            print(\"Exiting the translation tool. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Step 2: Preprocess the sentence\n",
    "        preprocessed = preprocess_sentence(original_sentence)\n",
    "        \n",
    "        # Step 3: Encode the preprocessed sentence\n",
    "        encoded = encode_input(preprocessed)\n",
    "        \n",
    "        # Step 4: Translate using the model\n",
    "        translated = decode_sequence(encoded)\n",
    "        \n",
    "        # Step 5: Print the translation\n",
    "        print(f\"Original Sentence: {original_sentence}\")\n",
    "        print(f\"Translated Sentence: {translated}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Run the interactive translation tool\n",
    "interactive_translation()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 200079,
     "sourceId": 441417,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7130674,
     "sourceId": 11516289,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 25160,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
